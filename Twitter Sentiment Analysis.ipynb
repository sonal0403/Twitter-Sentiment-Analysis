{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Live Streaming & Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "#Tweepy installation required for streaming twitter data \n",
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "\n",
    "#JSON library required for handling data returned from api calls\n",
    "import json, time, sys\n",
    "\n",
    "#NLTK library required for natural laguage processing\n",
    "import nltk\n",
    "from nltk import *\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify import ClassifierI\n",
    "\n",
    "#URLLIB required for creating url's\n",
    "import urllib\n",
    "\n",
    "# Matplotlib required for creating live graph\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import style\n",
    "\n",
    "#In working directory create a file called reqimports.py\n",
    "#Create twitter apps account and a new appliaction.\n",
    "#Using twitter apps account populate access token, access key, customer secret and customer key in regimports file\n",
    "#Register for a free language processing api key @ alchemyapi.com\n",
    "#Put alchemy api key in alap variable of reqimports \n",
    "from reqimports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Default variables to 0 \n",
    "xaxis = 0\n",
    "result = 0\n",
    "pos=0\n",
    "neg=0\n",
    "neu=0\n",
    "elm=0\n",
    "\n",
    "style.use(\"ggplot\")\n",
    "#Create container for graph\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Sentiment Analyzer module\n",
    "def sentanalyzer(t):\n",
    "#Takes some text and encodes it so that it can be passed in a URL    \n",
    "    passtext = urllib.quote(t)\n",
    "#Hold apikey value in a variable    \n",
    "    alapikey= alap\n",
    "#Call alchemyapi to retrive sentiment of passed text    \n",
    "    apicall = 'http://access.alchemyapi.com/calls/text/TextGetTextSentiment?text='+passtext+'&apikey='+alapikey+'&outputMode=json'\n",
    "#Read alchemyapi output and store in a variable    \n",
    "    json_string = urllib.urlopen(apicall).read()\n",
    "#Parse json to retrieve variables of interest\n",
    "    parsed_json = json.loads(json_string)\n",
    "#If alchemy returns error then return some text, else return the type of sentiment of the text passed(positive/negative/neutral)    \n",
    "    if (parsed_json['status'] == 'OK'):\n",
    "        return parsed_json['docSentiment']['type']\n",
    "    else:\n",
    "        return 'eliminated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter keyword to mine: happy\n"
     ]
    }
   ],
   "source": [
    "#Input box to take input from user, this keyword will be used to filter tweets, only tweets containing this keyword would be streamed.\n",
    "inputw = raw_input(\"Enter keyword to mine: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creates a listener class\n",
    "class listener(StreamListener):\n",
    "#Function specifying things to do when data found    \n",
    "    def on_data(self, data):\n",
    "#Clean twitter data, get rid of symbols and fetch text only (actual data has so much more)         \n",
    "        decoded = json.loads(data)\n",
    "        cleaned_tweet = (decoded['text'].encode('ascii', 'ignore'))\n",
    "#Pass cleaned tweet through sentiment analyzer module to get sentiment, store in sent_result variable\n",
    "        sent_result = sentanalyzer(cleaned_tweet)\n",
    "#Variables used in below calculation        \n",
    "        global xaxis\n",
    "        global result\n",
    "        global pos\n",
    "        global neg\n",
    "        global neu\n",
    "        global elm\n",
    "#For every single tweet increment xaxis by 1 (meaning xaxis holds total number of tweets)        \n",
    "        xaxis +=1\n",
    "#Based on sentment increment or decrement result (+ for pos, - for neg, 0 for neutral or error)  \n",
    "#Also store total number of pos, neg, neu, err tweets\n",
    "        if(sent_result == 'positive'):\n",
    "            result += 1\n",
    "            pos += 1\n",
    "        elif(sent_result == 'negative'):\n",
    "            result -= 1\n",
    "            neg += 1\n",
    "        if(sent_result == 'neutral'):\n",
    "            result += 0\n",
    "            neu += 1\n",
    "        elif(sent_result == 'eliminated'):\n",
    "            result += 0\n",
    "            elm += 1\n",
    "#Incrementally store results in text file.            \n",
    "        with open(\"tweet_sentiment_result.txt\", \"a\") as tweet_results:\n",
    "            tweet_results.write(\"%s,%s\\n\" % (xaxis, result))\n",
    "        with open(\"tweet_sentiments.txt\", \"a\") as tweet_sents:\n",
    "            tweet_sents.write(\"%s,%s,%s,%s\\n\" % (pos, neg, neu, elm))    \n",
    "        return True\n",
    "#Function specifying things to do if listener errors out    \n",
    "    def on_error(self, status):\n",
    "#Just prints status        \n",
    "        print status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create authentication handler\n",
    "auth = OAuthHandler(ckey, csecret)\n",
    "auth.set_access_token(atoken, asecret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Call listener\n",
    "twitterStream = Stream(auth, listener())\n",
    "#Stream tweets, filer by user specified keyword\n",
    "twitterStream.filter(track=[inputw])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a list of all words in movie_reviews along with their categories (pos/neg)\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Shuffle words and create a list with all words\n",
    "random.shuffle(documents)\n",
    "all_words = []\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "#Get count for all words\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "#Create a list of top 3000 words\n",
    "word_features = list(all_words.keys())[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function to find features in passed sentence\n",
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create set of features, a list of feature-category\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "#Divide feature set into training and test\n",
    "training_set = featuresets[0:1900]\n",
    "testing_set = featuresets[1900:]\n",
    "#print(testing_set)\n",
    "#Create classifier using NLTK's naive bayes classifier and movie_review corpus\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "#print(classifier)\n",
    "classifier.show_most_informative_features(15)\n",
    "#Check acuracy of created classifier\n",
    "print(\"Classifier accuracy percent:\",(nltk.classify.accuracy(classifier, testing_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to extract sentiment of passed sentence using naive bayes classifier trained using movie_reviews corpus\n",
    "def sentiment(text):\n",
    "    feats = find_features(text)\n",
    "    #print(text)\n",
    "    return classifier.classify(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Manually checking if the naive bayes algorithm works as expected\n",
    "sentiment(\"This is amazing, I totally recommend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Manually checking if alchemy api gives correct sentiment for text passed\n",
    "sentanalyzer(\"This is amazing, I totally recommend\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
